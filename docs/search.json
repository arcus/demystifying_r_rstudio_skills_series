[
  {
    "objectID": "session_1.html#welcome",
    "href": "session_1.html#welcome",
    "title": "",
    "section": "Welcome",
    "text": "Welcome\nThese slides available at: https://arcus.github.io/demystifying_r_rstudio_skills_series/session_1.html\n\nUse keyboard arrow keys to\n\nadvance ( → ) and\ngo back ( ← )\n\nType “s” to see speaker notes\nType “?” to see other keyboard shortcuts\n\n\nAs we prepare to get started, I’d like to encourage you to open these slides on your own browser, so you will have them available to refer to later. There are also a number of links you may want to click on. I’ll copy paste that URL, where the slide deck is located, into chat, so everyone has it.\nThis first slide is just to help you navigate this slide deck if you look at these slides on your own! And yes, there are ample speaker notes, so if you missed something I said, chances are it’s going to be in the speaker notes of the slide."
  },
  {
    "objectID": "session_1.html#about-arcus-your-presenter",
    "href": "session_1.html#about-arcus-your-presenter",
    "title": "",
    "section": "About Arcus / Your Presenter",
    "text": "About Arcus / Your Presenter\n\n\nArcus is an initiative by the Research Institute aimed at promoting data discovery and reuse and increasing research reproducibility.\n\nArcus app: https://arcus.chop.edu\nArcus Sharepoint site: https://chop365.sharepoint.com/sites/Arcus\n\nAmong the many teams in Arcus, I represent Arcus Education!\n\n\n\n\n\nThanks again for joining us, and welcome to our session today! I’d like to begin by briefly introducing myself and introducing Arcus, for those of you who may not be familiar with us. My name is ______ [add pronouns here if you want], and I’ll be leading today’s session.\nArcus is an initiative by the Research Institute aimed at promoting data discovery and reuse and increasing research reproducibility throughout the research lifecycle, as you can see in the graphic on the right. [Pause, give folks a few secs to peruse the image].\nChanging the paradigm of research is a big undertaking, and it requires a broad approach.\nWe aim to improve data reuse and research reproducibility at CHOP through technology, including Arcus labs and applied data science, through the use of data archiving and cataloging, and by way of education.\nYou can find out more by checking out the Arcus application website (please note, there are some pre-requisites to using the app, such as human subjects protection training and signing our terms of use). I’ve added just a very small screenshot of part of what the Arcus application website looks like on the slide on the left side. [Pause].\nYou can also, without any prerequisites, look at our Arcus Sharepoint site, which has a calendar of events and lots more information about Arcus.\nAnd finally, a little more about me: I work in Arcus Education. Our role is to support CHOP scientists by helping researchers acquire data science skills. That’s why we have Skills Series like this one!"
  },
  {
    "objectID": "session_1.html#arcus-education",
    "href": "session_1.html#arcus-education",
    "title": "",
    "section": "Arcus Education",
    "text": "Arcus Education\n\n\n\n\nArcus education provides data science training to researchers …\n(and often this is useful to non-researchers too!).\nhttps://arcus.chop.edu/i-want-to/arcus-education\nEmail us! arcus-education@chop.edu\n\n\nThe Arcus Education team does lots of different kinds of education. We work one on one with researchers in office hours, we write how-to guides to help people understand how to use Arcus tools, we create asynchronous modules that people can use to acquire skills in their own time, and we do synchronous events like this one.\nSometimes we focus on Arcus customers, on researchers at CHOP who are doing research within the Arcus data sharing paradigm, and sometimes we broaden our reach to larger audiences, because we know that helping everyone acquire data science skills will help improve the conduct of science at CHOP and help build a data-driven workforce.\nPlease check out that education page and find out more about some of our services. You can see I’ve added a screenshot of that page to the slide here on the left side. You can also email us at arcus dash education at chop dot edu."
  },
  {
    "objectID": "session_1.html#demystifying-r-and-rstudio",
    "href": "session_1.html#demystifying-r-and-rstudio",
    "title": "",
    "section": "Demystifying R and RStudio",
    "text": "Demystifying R and RStudio\nArcus Education provides “Skills Series” for the entire CHOP community.\nThis Skills Series is a short, 2-session series aimed at Demystifying R and RStudio!\n\nSession 1: Introduction to R/RStudio\nSession 2: Introduction to Literate Statistical Programming\n\n\nOne of our methods in Education is the Skills Series, and that’s what you’re in today.\nIn this series, we’re going to take just two sessions to help demystify R and RStudio. If you have heard people talk about these concepts and you have only a vague idea what they are, and want to know more, without having to actually download anything or write code, at least not yet, this is the right series for you.\nAfter you finish these two sessions, you’ll understand what R is, what RStudio is, why people use these tools, and next steps for getting access to them, if you want."
  },
  {
    "objectID": "session_1.html#session-1-itinerary",
    "href": "session_1.html#session-1-itinerary",
    "title": "",
    "section": "Session 1 Itinerary",
    "text": "Session 1 Itinerary\nIntroduction to R/RStudio\n\nR is a programming language created for statistical data analysis\nWhy scripts? Reproducibility and open source data science\nRStudio is one way to work with R\nConsiderations for working with R and RStudio at CHOP\nPosit.Cloud\n\nGoals:\n\nBe able to describe the difference between R and RStudio\nBe able to give one advantage for using scripts written in R for data analysis\nHave a concrete next step for knowing how to get R and RStudio at CHOP\n\n\nSo let’s get started with this first session. In this session we’re going to cover an introduction to R and RStudio.\nWe’ll go over what R is, and why people use it.\nWe’ll then talk about why people like to use RStudio to write in R.\nWe’ll discuss ways to use R and RStudio at CHOP, and we’ll also talk about an online option called Posit dot cloud."
  },
  {
    "objectID": "session_1.html#r-is-a-programming-language",
    "href": "session_1.html#r-is-a-programming-language",
    "title": "",
    "section": "R is a Programming Language",
    "text": "R is a Programming Language\nR is a programming language. This is what it looks like:\n\n# Ingest data from REDCap\narcus_101_feedback_token &lt;- readr::read_file(\"secrets/quick_arcus_101_feedback_token.txt\")\narcus_101_feedback &lt;- get_data(arcus_101_feedback_token)\n\n# Get raw data and add the labels back in the correct order, show change over time\narcus_101_feedback_updated &lt;- arcus_101_feedback %&gt;%\n  \n  # We don't need the \"completeness\" value\n  select(-arcus_101_effectiveness_complete) %&gt;%\n  \n  # Transform all the \"knowledge\" questions\n  mutate(across(starts_with(\"knowledge\"),\n                ~ factor(.x, levels = c(\"Very little knowledge\", \n                                      \"Some knowledge\", \n                                      \"Lots of knowledge\", \n                                      \"Expert\"))),\n         \n         # Transform all the \"opinion\" questions (pre)\n         opinion_pre = factor(opinion_pre, \n                              levels = c(\"Largely negative, I didn't think Arcus was useful or helpful to CHOP.\", \n                                         \"Somewhat negative, I had doubts about how useful or helpful Arcus was to CHOP.\", \n                                         \"Neutral, I didn't have a strong opinion.\",\n                                         \"Somewhat positive, I believed that Arcus was useful or helpful to CHOP.\", \n                                         \"Largely positive, I was certain that Arcus was useful or helpful to CHOP.\")),\n         \n         # Transform all the \"opinion\" questions (post)\n         opinion_post = factor(opinion_post, \n                              levels = c(\"Largely negative, I don't think Arcus is useful or helpful to CHOP.\", \n                                         \"Somewhat negative, I have doubts about how useful or helpful Arcus is to CHOP.\", \n                                         \"Neutral, I don't have a strong opinion.\",\n                                         \"Somewhat positive, I believe that Arcus is useful or helpful to CHOP.\", \n                                         \"Largely positive, I am certain that Arcus is useful or helpful to CHOP.\")),\n         \n         # Measure change (pre to post)\n         \n         knowledge_change = as.numeric(knowledge_post)-as.numeric(knowledge_pre),\n         opinion_change = as.numeric(opinion_post)-as.numeric(opinion_pre),\n         )\n\n# Make a bar chart showing pre-intervention knowledge\n\nggplot(arcus_101_feedback_updated) +\n         geom_bar(aes(x=knowledge_pre)) +\n  scale_x_discrete(drop=FALSE) +\n  labs(title = \"Knowledge of Arcus Before 101\") +\n  xlab(\"\")\n\n# Save this graph for later\n\nggsave(\"figures/pre_101_knowledge.png\")\n\n\nOK, if you’ve never seen any R language before, here’s an example. This is real R code that we use in my team. This is just to show you what R looks like, so you get an idea.\nYou can see that there are some comments, here shown in grey, that describe what the code is doing. As I scroll down, you can see what this code does.\nFirst, we’re ingesting some data from REDCap. It’s a survey we give related to a webinar we offer twice a month, called Arcus 101. We want to measure our effectiveness, and we analyze this survey data using R.\nSo we ingest the data,\nIn line 9, we get rid of a value we don’t need.\nThen we do some transformation. We want to make sure R knows the proper order of our Likert scale values. We have a set of values that has to do with knowledge, a set of values that has to do with opinion before our talk, with verbs in the past tense, and a set of values that has to do with opinion after our talk, which has verbs in the present tense.\nIn lines 36 and 37, we do a little math to measure change.\nThen we make a data visualization in lines 42 through 46 – a bar graph – and in line 50, we save this as a file we can use later.\nThis is just a snippet of actual code that we use in our team, just in case you’ve never seen R code before."
  },
  {
    "objectID": "session_1.html#r-is-a-programming-language-1",
    "href": "session_1.html#r-is-a-programming-language-1",
    "title": "",
    "section": "R is a Programming Language",
    "text": "R is a Programming Language\nR is a statistical programming language.\n\nLike other programming languages (Javascript, Python, C++):\n\nR has specific syntax rules\nR gives error messages that you might have to search online for\nR has online communities that can help you learn (Stack Overflow, etc.)\n\nUnlike other programming languages:\n\nR was written specifically for statistical data analysis\n\n\n\nIf you ever took programming in school, whether that was BASIC or Pascal or C++ or Python, you will have a little bit of an advantage in learning R. That’s because R is a programming language. Like other programming languages, R has specific syntax rules. When you make mistakes, which is very very normal, R will give you error messages that might seem cryptic at first until you get used to them. Because learning to write a programming language can be hard, there are lots of online communities where people help each other out and ask questions. R is similar to other programming languages in these ways.\nBut R is special as a programming language when we’re talking about data. While all programming languages can work with data, R was designed specifically for data analysis. That means that that R is really quite good for data analysis, and it’s not good for, say, programming robots."
  },
  {
    "objectID": "session_1.html#why-does-this-matter",
    "href": "session_1.html#why-does-this-matter",
    "title": "",
    "section": "Why Does This Matter?",
    "text": "Why Does This Matter?\n\n\nWhich is a better tool?\n\nA multi-tool (like a Swiss Army knife)\nA mostly mono-task tool (like a cherry pitter)\n\nIt depends! R is more focused / narrow… which can be good for beginners.\n\n “Stainless 2CR Multi-tool”, Santeri Viinamäki, CC BY-SA 4.0, via Wikimedia Commons\n\n\nThere are programming languages that can do lots of stuff reasonably well. Python is one. Python is like a multi-tool. With Python, you can make a website, or program a robot, or analyze data, or make a desktop application, or build an API. You can get lots of different attachments, or libraries, to make the language more useful. That’s great if you’re an experienced programmer and you need to do lots of different things. It seems like a multi-purpose language would be the best choice for most people, right?\nWell, one thing to consider is what happens when you’re a beginner. When you’re learning something for the first time, it can be a lot easier to learn how to use a tool that mostly just does one thing. If you’re using code to do data analysis, and you’re searching online for tutorials, it can be very frustrating to watch a bunch of tutorials that end up being about how to program robots or do other things that you don’t care about. Because R is a very tightly scoped solution to the problem of data analysis, everyone who is posting about R on the internet is interested in data analysis, and you’ll have a lot easier time finding answers to your questions about how to use it.\nSo, to answer the question on this slide… which is better? It depends! We think – and it’s just our opinion – that for people who have to do lots of different things, a multi-tool, a language that has lots of uses, like Python, might be a better fit. And we suspect that for beginners, a very focused tool like the R language might be a better fit as you get started."
  },
  {
    "objectID": "session_1.html#why-not-just-use-excel",
    "href": "session_1.html#why-not-just-use-excel",
    "title": "",
    "section": "Why Not Just Use Excel?",
    "text": "Why Not Just Use Excel?\n\n\n“Why even write code? Point and click is so much easier!”\nThese can be useful:\n\nExcel\nPoint and click statistical analysis software (e.g. SPSS, SAS)\n\nBut they can also be:\n\nVery manual / lots of steps you have to explain\nCostly\n\nOne potential answer? Scripts!\n\n\n\nUsed with permission by Ed Himelblau. See his work or subscribe to his newsletter at https://www.himelblau.com/\n\n\n\nHere’s a question you might be asking:\nWhy do people even bother to learn how to write code to analyze data? After all, there are software programs out there that allow you to use point and click to analyze your data. Many people use Excel for day-to-day data analysis, and for scientific-grade statistical analysis, there’s always programs like SPSS or SAS or Stata.\nAnd we think that a lot of this depends on how often you’re going to do a particular analysis and if you have to share it, and with whom.\nIf you’re going to do something once, or very infrequently, and it’s just for you or for a few people, for example, let’s say it’s your annual budget, just do a spreadsheet in Excel. No need to write code to do a one-off thing.\nHowever, if you’re going to need to repeat your analysis over and over again, or have someone else do it, think about the steps you take. Will it be hard to describe exactly what cell to put data in, and how to click and drag the values in just the right way? If there are lots of steps and doing things manually is error prone, hard to describe, or just plain annoying, you might not actually write down your steps. You might think, “I’ll remember this”, or “It’ll be obvious to me later.” Spoiler alert: it might not be! In a case of lots of steps, you might be better off writing a script.\nAlso, if you’re going to be sharing your materials beyond your team, you have to think about cost. Excel costs, what, maybe $100? I’m not sure. But other software like SAS or Matlab or SPSS can cost hundreds or thousands of dollars, and if you are using that software and sharing your files with someone who doesn’t have the program, you may be making their life complicated. One of the great things about R is that it’s a free, open source language that people around the world use. It’s very popular and anyone can download and use it for free."
  },
  {
    "objectID": "session_1.html#scripts",
    "href": "session_1.html#scripts",
    "title": "",
    "section": "Scripts",
    "text": "Scripts\nIn data analysis, scripts are a series of computer code instructions that handle things like:\n\nIngesting data\nPreparing data\nDoing descriptive statistics\nConducting statistical tests\nCreating models\nSaving interim datasets\nCreating data visualizations\nCommunicating information\n\n\nScripts, in this context, are computer code that allow you do do things like:\n\nIngesting data: for example, bringing in a .csv file or downloading the latest data from REDCap.\nPreparing data. This could be something like removing outliers or combining data from two or more sources.\nReporting statistical characteristics. Maybe you want to find quartiles or median values for your data.\nConducting statistical tests. If you do research, you might need to do something like a two-sample t-tests or measure Cohen’s effect size.\nCreating models. Maybe you want to create a linear model that would allow you to predict future performance, given what you know from current data.\nSaving interim datasets. Perhaps you want to save a deidentified version of data, or a cleaned up version for senior leadership.\nCreating data visualizations like scatter plots or box plots\nCommunicating information like making a dashboard for leadership or a table for a scientific publication.\n\nR allows you to write a script where you instruct the computer in how to do each step of this process.\nWriting a script in a coding language like R is hard, but once it’s done, you can have a script that does all the steps of your analysis without having any manual intervention. That means you can execute it again later (or someone else can), and all that hard work pays off."
  },
  {
    "objectID": "session_1.html#why-scripts",
    "href": "session_1.html#why-scripts",
    "title": "",
    "section": "Why Scripts?",
    "text": "Why Scripts?\n\n\nIn science, we’ve been hearing a lot about the “reproducibility crisis”.\nIt’s hard to re-do other people’s analyses… both for checking their work and for trying it in a new situation. This is bad for science!\nOne of the most important reasons to learn R is to improve the reproducibility of your work. One of the most powerful aspects of working in the R environment is that it makes it straightforward to produce reproducible data analyses, which will reduce risk and make “future you” much happier.\n\n\n\nUsed with permission by Ed Himelblau. See his work or subscribe to his newsletter at https://www.himelblau.com/\n\n\n\nI’m going to talk about the reproducibility crisis here. Give me a thumbs up emoji if you’re already familiar with this term.\nNow, I know not everyone on this call might work principally in research, so I want to start by saying that one of the important things in science is that we have to repeat experiments to see if we see things happen over and over again. And that’s because sometimes we see experimental results that are just coincidences or luck.\nIf we see that a certain type of therapy reduces anxiety in one study, we want to see that it works again and again. We want to try it in adolescents, and in adults, and in city kids, and in rural communities, and we’d like to see it work in English speakers and maybe outside of the USA, and in groups with different socio-economic backgrounds, etc. That’s part of how science works. We repeat experiments.\nWe try the same things in different populations. We want to see if the same drug works similarly in men and in women, and in people of various weights, and different comorbid conditions.\nIt’s helpful if different scientists in different organizations and in different parts of the world can show that they’re seeing the same effects. It means increasing scientific evidence.\nThe “reproducibility crisis” refers to the problem in peer-reviewed research in which studies cannot be redone, cannot be reproduced, maybe because of insufficient information on how to redo them, or maybe because of preventable problems in the initial research.\nScience usually has a long, multi-step process for gathering and analyzing data, and any multi-step process can be prone to error. It can be prone to error even when you yourself are doing the exact same analysis three months later when a new batch of data comes in! And it’s even more error prone when someone who isn’t you is trying to understand your notes and how you did things.\nThe cartoon on the right, which is by biologist and New Yorker cartoonist Ed Himelblau, shows scientists doing some very complex rituals as part of trying to reproduce an experiment. I know the caption is quite small, so I’ll read it. It says, “Do you ever wonder if every step in the protocol is absolutely necessary?”\nThat’s why having an automated script, which handles all of the steps without human intervention, can be really very helpful. And now that we’re facing an economy where we have to do more with less, the ability to automate things for free, without an expensive license, is really useful, especially if you want to share your findings with colleagues in lower-resourced settings.\nWe’ll talk more about reproducibility in the second session of this two-webinar series, where we talk about literate statistical programming, so if this is interesting to you, please come back for the second talk!"
  },
  {
    "objectID": "session_1.html#r-vs-rstudio",
    "href": "session_1.html#r-vs-rstudio",
    "title": "",
    "section": "R Vs RStudio",
    "text": "R Vs RStudio\n\n\n\n\n\n\n\n\nR Programming language for data analysis\n\nRStudio Integrated development environment (IDE)\n\n\nHopefully you understand why sometimes, for at least some people, working with R to write scripts for data analysis makes sense. It can save time and make their work more reproducible and shareable in the long run. Now I want to distinguish between two very similar terms.\nThe first is R. R is a statistical programming language that’s great for doing data analysis. We’ve already talked about a few things that make R useful:\n\nR was built specifically for statistical data analysis, so it’s got a friendly and focused user community and lots of great online resources for learning.\nR is open source, which means that it is “free” in two ways – in the meaning of having no cost and also in that can be used widely without intellectual property concerns or licensing restrictions.\nR makes it possible to work with data and build scripts that do lots of things, from ingesting data to building data visualizations.\n\nSo that’s R, it’s a language with a lot of benefits.\nThen, there’s RStudio. RStudio was the original name of a company as well as the name of a piece of software the company makes (and there is a free and a paid version of this software). A couple of years ago, the company changed its name from RStudio to Posit, but they kept the old name on at least some of their software.\nYou can think of RStudio (the software) as a fancy text editor for writing R code. The technical term for a fancy text editor for writing code is “Integrated Development Environment”, or I-D-E. You can run RStudio on Mac, Windows, or Linux. It can run on a local computer like your laptop, or on a server that is accessed using a web browser.\nYou don’t have to use RStudio to write R, but it makes it a lot easier. Think about typing a paper in Microsoft Word. You don’t need to use Word, necessarily. If you didn’t have Microsoft Word, you could write down your thoughts in Notepad, or in a blank Outlook email, or in the Notes app on your phone. But Microsoft Word has lots of add-ons, like spell-check and word count and formatting that make it much more pleasant to write a paper there, rather than in the notes app on your phone!"
  },
  {
    "objectID": "session_1.html#using-r-alone-vs-with-rstudio",
    "href": "session_1.html#using-r-alone-vs-with-rstudio",
    "title": "",
    "section": "Using R Alone vs With RStudio",
    "text": "Using R Alone vs With RStudio\n\n\n\n\n\n\n\n\n\n\n\n\n\nNow, you can download the R language by itself, and it comes with a little application for writing R code. It’s not a terrible application, but it doesn’t have many features. On the left, you can see what the R application by itself looks like.\nPosit is a company that is separate from the people who are in charge of the R language, but they make a fantastic piece of software that we strongly recommend, called RStudio. It’s free, and you can see RStudio on the right.\nRStudio has lots of included features that make working in R a lot easier, and most everyone who works in R uses RStudio to write their code. We highly recommend you use it!\nIn the next slide, I’ll show you an animation of what working with just plain R looks like, so you can get a baseline feel for what that’s like, and then in the following slide I’ll show you what it can look like to work with RStudio, so you can appreciate the difference."
  },
  {
    "objectID": "session_1.html#the-r-app",
    "href": "session_1.html#the-r-app",
    "title": "",
    "section": "The R App",
    "text": "The R App\n\n\nOK, so here I’m going to run code on the left and it will be executed on the right. You can execute code using a keyboard shortcut or by using the dropdown menu. You can see that graphics appear in a separate window. And I’m creating a few different graphics, and those are all creating files, somewhere in my folder that contains this code. If I want to see the folder that contains them all, I have to open a new program. I use a Mac, so in my case that’s Finder, and I can see those files. Finally, I can use the Help function, and a separate window opens up. That’s the R app. It’s not terrible, but it’s not great, either. And that graphic is just going to loop, so I’ll go ahead to the next slide."
  },
  {
    "objectID": "session_1.html#rstudio",
    "href": "session_1.html#rstudio",
    "title": "",
    "section": "RStudio",
    "text": "RStudio\n\n\nIn RStudio, we can run these bits of code called code chunks here, and we can run them one at a time, or we can run “all chunks above”, if we want to just run a lot of code chunks in a row.\nWe can see the plots in a couple of different places in RStudio, depending on our preferences, and we can see our files listed out right in RStudio, in that lower right pane, and click on our files to open them and see them in a file viewer.\nHelp is also located in a pane in the same window, which can be helpful.\nI can also take a look at the data I’ve ingested and get an idea of what my survey data looks like.\nFinally, I can also create a report by “rendering” my code and making an HTML report that includes my code, some sentences and headers I wrote that help describe my code, and shows the graphs I made. This kind of report creation is a big reason why some people use RStudio. RStudio supports the creation of dashboards and reports that help you not only analyze your data, but communicate what you’ve discovered to different kinds of audiences.\nIf you want to learn more about that, come to the next talk in this series, called literate statistical programming."
  },
  {
    "objectID": "session_1.html#rstudio-runs-lots-of-places",
    "href": "session_1.html#rstudio-runs-lots-of-places",
    "title": "",
    "section": "RStudio: Runs Lots of Places",
    "text": "RStudio: Runs Lots of Places\n\n\n \n\n \n\n\n\n\n\nPosit.cloud\nHosted by Posit (in the cloud)\n\nPosit Workbench\nHosted by a company, on prem or in the cloud\n\nRStudio Desktop\nInstalled on your computer\n\n\nThere are several versions of RStudio:\nPosit.Cloud – a version of the RStudio IDE that can be accessed from a web browser. It’s hosted on a server by Posit, the company that makes this software. It’s literally at the URL posit.cloud!\nPosit Workbench – a version of the RStudio IDE that can also be accessed from a web browser. But this time, it’s hosted by a private business on a server, such as on a server your department runs that everyone in your team can access.\nRStudio Desktop – a version of the RStudio IDE that is installed on a personal device like your desktop or laptop computer. This is what most people at CHOP use, installing it on their CHOP devices or using it on a virtual device like a VDI.\nIt’s important to note that regardless of which version of RStudio that you use, you will be accessing the same general product. All of these pretty much look and act the same. So let’s get into what you might need to do at CHOP if you want to work with R and RStudio!"
  },
  {
    "objectID": "session_1.html#working-with-r-at-chop",
    "href": "session_1.html#working-with-r-at-chop",
    "title": "",
    "section": "Working with R at CHOP",
    "text": "Working with R at CHOP\n\nWe work with regulated data\nIRB protocols and other regulations might override what I say here!\nYou can work with R and RStudio on a CHOP device\n\nYou will probably have to request an install via a service ticket\nYou’ll need a cost center / grant / project number (even though there’s no cost)\nYes, this software has been used at CHOP before\nYou’ll need to give a reason (“I need to analyze data for my job…”)\nYou’ll need to provide the MAC address of your computer\n\n\n\nFirst, a few caveats to keep in mind. At CHOP, we work with sensitive data, whether that’s health care data, research data, or trade secrets about our enterprise. We want to be careful. You will almost certainly need to put in a ticket to get the right software installed on your CHOP device. At this point, if you’re not already following along in the slides, I’m going to really encourage you to grab this slide link because this slide and the next will have important information that will be useful for you when you decide to work with R and RStudio. I will also point out that I do not work for DTS and I cannot approve or install software for you… you have to go through the formal channels here and I don’t have any shortcuts!\nEven though all of these software are free, you’ll need a Cost Center (or grant fund) to add to your request. Get that from your manager, administrative staff, or other leadership within your area. There will be no charge, but DTS uses this information for tracking resource utilization. You’ll be asked if this is software that’s already in use at CHOP – it certainly is. You’ll be asked to provide a justification, and that’s usually that you need this to do data analysis for your job. And finally, you’ll have to provide information about your workstation, including the MAC address of your computer."
  },
  {
    "objectID": "session_1.html#what-to-get-installed",
    "href": "session_1.html#what-to-get-installed",
    "title": "",
    "section": "What To Get Installed",
    "text": "What To Get Installed\nWhat I recommend you install / get installed on your own CHOP device:\n\nR – the language we use to clean, analyze, and visualize data\nRStudio Desktop – an IDE for writing R\nGit – version control software that will allow you to easily get the latest version of our course materials and will also be helpful for tracking changes in your own projects\nGitHub Desktop – a helper, or “client” software that makes working with Git easier\n\n\nWe’ve already talked about R and RStudio, but I also highly recommend getting Git and GitHub Desktop installed as well. They work really well with RStudio, and even if you’re not ready to work with version control software now, you might want to work with these programs in the future, so it can be helpful to have everything installed all at once. Each of these links can take you to more information about installing these programs, which can be helpful for talking to DTS or your boss."
  },
  {
    "objectID": "session_1.html#researchers-only-at-chop",
    "href": "session_1.html#researchers-only-at-chop",
    "title": "",
    "section": "Researchers ONLY at CHOP",
    "text": "Researchers ONLY at CHOP\n(You’ll need a research cost center to refer to for most of these)\n\nIf you work with the High Performance Compute cluster (HPC or Respublica), you can request an RStudio session by logging in to Interactive Apps and choosing RStudio.\nYou can request a VDI that includes RStudio.\nYou can request an Arcus lab for a well-defined research project you’re planning. The Arcus lab includes RStudio.\n\n\nIf you’re a researcher at CHOP, there are additional places you might want to use R and RStudio. And keep in mind, I work on the research side, so this is what I know best. If you’re on the clinical or operational side of CHOP, or you work for Foundation, and there’s something about working with R and RStudio on your side that I’ve omitted, please let me know so I can update the slides!\nI won’t go into these in detail, but each of these are links that take you to more information. As a researcher, you can request access to the HPC, also known as Respublica, you can request a VDI, or you can request an Arcus lab. All of these can be ways you can get access to R and RStudio without having to install them on your local computer. And especially if you work with very big data, or you do complex, high-memory data modeling, you might have to use some of these resources, if your computer just doesn’t have enough RAM to do the job. But as always, please make sure that wherever you work with your data, you are in compliance with your IRB protocol and any other regulation."
  },
  {
    "objectID": "session_1.html#posit.cloud-be-careful",
    "href": "session_1.html#posit.cloud-be-careful",
    "title": "",
    "section": "Posit.Cloud (be careful!)",
    "text": "Posit.Cloud (be careful!)\nYou can use R and RStudio using online services like https://posit.cloud.\nPosit.cloud is a great place for learning or practice with public datasets, BUT is not a safe or compliant place to put your regulated data.\n\nWhen we teach R and RStudio, it can be next to impossible to deal with everyone’s different kinds of installation issues while they’re trying to get set up and deal with IS, get issues ironed out with their computers and their access permissions, etc.\nThat’s why we usually have brand new students use Posit.cloud to learn R and RStudio. Posit.cloud is an online, cloud based service provided by Posit, the company that makes the RStudio software. It’s really good and reliable and it has a very generous free tier! It means that as teachers we can concentrate on our learners really acquiring the skills around R and RStudio, without being bogged down by the fact that some people have Macs, some have PCs, some have admin rights, some don’t, some have R installed, some don’t, some have a very old version of R and they can’t update it, and so on. Using Posit.cloud makes things a lot easier for teachers and learners.\nHOWEVER! Posit is absolutely NOT an appropriate place for regulated health care data. It’s for practicing and learning using public datasets. If you’re going to use R for CHOP data, you might benefit from learning R and RStudio using Posit.cloud but at the same time start the process of getting R and RStudio installed on your CHOP device so that you can transfer those skills to real-life work right away. Depending on your operating system and what you already have installed, this might be very smooth, or you might have to troubleshoot this a few times with DTS or RIS, so be prepared to be patient."
  },
  {
    "objectID": "session_1.html#qa-was-this-effective",
    "href": "session_1.html#qa-was-this-effective",
    "title": "",
    "section": "Q&A / Was This Effective?",
    "text": "Q&A / Was This Effective?\nAs you can tell from our data analysis, we like to measure our effectiveness.\nGoals:\n\nBe able to describe the difference between R and RStudio\nBe able to give one advantage for using scripts written in R for data analysis\nHave a concrete next step for knowing how to get R and RStudio at CHOP\n\n\nNow, this is not the final slide, but we’re a group that likes to measure our effectiveness and make changes based on what we learn. So before we do questions and answers, we like to make sure to give our learners a poll to see if we made a good use of your time. We’re going to ask if we were effective in reaching our goals today, and those goals are on the screen in order to help you answer that question. Once you answer that poll, feel free to type a question into chat or come off mute and ask to clarify anything I can explain a bit better. I’ll stop our session of Q&A with about 5 minutes to spare because I do have just a couple of finishing slides I want to show."
  },
  {
    "objectID": "session_1.html#homework",
    "href": "session_1.html#homework",
    "title": "",
    "section": "Homework",
    "text": "Homework\nIf you want, totally optional additional learning:\n\n\n\nModule\nDescription\nDuration\n\n\n\n\nLearning to Learn Data Science\nDiscover how learning data science is different than learning other subjects.\n20 mins\n\n\nReproducibility, Generalizability, and Reuse\nThis module provides learners with an approachable introduction to the concepts and impact of research reproducibility, generalizability, and data reuse, and how technical approaches can help make these goals more attainable.\n60 min\n\n\n\n\nOK, as we get close to the end, I know that for some people, this topic ignited a bit of excitement about the ideas around learning how to code or learning more about reproducibility. If that’s you, we have a couple of resources here that you might enjoy, but you absolutely do not have to use these to be able to enjoy and profit from the next session of this series."
  },
  {
    "objectID": "session_1.html#next-session",
    "href": "session_1.html#next-session",
    "title": "",
    "section": "Next Session",
    "text": "Next Session\nLiterate Statistical Programming (DATES HERE)\n\nReview of R and RStudio\nLiterate programming is a programming paradigm\nResearch reproducibility reminders\nQuarto documents\nNext steps\n\n\nFinally, if you want to attend the next talk in this two-webinar series, we’ll be talking about Literate Statistical Programming, and here are some of the topics we’ll talk about next time.\nThanks so much for your time today, and have a great rest of your day!\n\n\n\n\n\nArcus Education, Children’s Hospital of Philadelphia"
  },
  {
    "objectID": "Untitled.html#welcome",
    "href": "Untitled.html#welcome",
    "title": "",
    "section": "Welcome",
    "text": "Welcome\nThese slides available at: https://arcus.github.io/demystifying_r_rstudio_skills_series/session_2.html\n\nUse keyboard arrow keys to\n\nadvance ( → ) and\ngo back ( ← )\n\nType “s” to see speaker notes\nType “?” to see other keyboard shortcuts\n\n\nAs we prepare to get started, I’d like to encourage you to open these slides on your own browser, so you will have them available to refer to later. There are also a number of links you may want to click on. I’ll copy paste that URL, where the slide deck is located, into chat, so everyone has it.\nThis first slide is just to help you navigate this slide deck if you look at these slides on your own! And yes, there are ample speaker notes, so if you missed something I said, chances are it’s going to be in the speaker notes of the slide."
  },
  {
    "objectID": "Untitled.html#about-arcus-your-presenter",
    "href": "Untitled.html#about-arcus-your-presenter",
    "title": "",
    "section": "About Arcus / Your Presenter",
    "text": "About Arcus / Your Presenter\n\n\nArcus is an initiative by the Research Institute aimed at promoting data discovery and reuse and increasing research reproducibility.\n\nArcus app: https://arcus.chop.edu\nArcus Sharepoint site: https://chop365.sharepoint.com/sites/Arcus\n\nAmong the many teams in Arcus, I represent Arcus Education!\n\n\n\n\n\nThanks again for joining us, and welcome to our session today! I’d like to begin by briefly introducing myself and introducing Arcus, for those of you who may not be familiar with us. My name is ______ [add pronouns here if you want], and I’ll be leading today’s session.\nArcus is an initiative by the Research Institute aimed at promoting data discovery and reuse and increasing research reproducibility throughout the research lifecycle, as you can see in the graphic on the right. [Pause, give folks a few secs to peruse the image].\nChanging the paradigm of research is a big undertaking, and it requires a broad approach.\nWe aim to improve data reuse and research reproducibility at CHOP through technology, including Arcus labs and applied data science, through the use of data archiving and cataloging, and by way of education.\nYou can find out more by checking out the Arcus application website (please note, there are some pre-requisites to using the app, such as human subjects protection training and signing our terms of use). I’ve added just a very small screenshot of part of what the Arcus application website looks like on the slide on the left side. [Pause].\nYou can also, without any prerequisites, look at our Arcus Sharepoint site, which has a calendar of events and lots more information about Arcus.\nAnd finally, a little more about me: I work in Arcus Education. Our role is to support CHOP scientists by helping researchers acquire data science skills. That’s why we have Skills Series like this one!"
  },
  {
    "objectID": "Untitled.html#arcus-education",
    "href": "Untitled.html#arcus-education",
    "title": "",
    "section": "Arcus Education",
    "text": "Arcus Education\n\n\n\n\nArcus education provides data science training to researchers …\n(and often this is useful to non-researchers too!).\nhttps://arcus.chop.edu/i-want-to/arcus-education\nEmail us! arcus-education@chop.edu\n\n\nThe Arcus Education team does lots of different kinds of education. We work one on one with researchers in office hours, we write how-to guides to help people understand how to use Arcus tools, we create asynchronous modules that people can use to acquire skills in their own time, and we do synchronous events like this one.\nSometimes we focus on Arcus customers, on researchers at CHOP who are doing research within the Arcus data sharing paradigm, and sometimes we broaden our reach to larger audiences, because we know that helping everyone acquire data science skills will help improve the conduct of science at CHOP and help build a data-driven workforce.\nPlease check out that education page and find out more about some of our services. You can see I’ve added a screenshot of that page to the slide here on the left side. You can also email us at arcus dash education at chop dot edu."
  },
  {
    "objectID": "Untitled.html#demystifying-r-and-rstudio",
    "href": "Untitled.html#demystifying-r-and-rstudio",
    "title": "",
    "section": "Demystifying R and RStudio",
    "text": "Demystifying R and RStudio\nArcus Education provides “Skills Series” for the entire CHOP community.\nThis Skills Series is a short, 2-session series aimed at Demystifying R and RStudio!\n\nSession 1: Introduction to R/RStudio\nSession 2: Introduction to Literate Statistical Programming\n\n\nOne of our methods in Education is the Skills Series, and that’s what you’re in today.\nIn this series, we’re going to take just two sessions to help demystify R and RStudio. If you have heard people talk about these concepts and you have only a vague idea what they are, and want to know more, without having to actually download anything or write code, at least not yet, this is the right series for you.\nAfter you finish these two sessions, you’ll understand what R is, what RStudio is, why people use these tools, and next steps for getting access to them, if you want."
  },
  {
    "objectID": "Untitled.html#session-2-itinerary",
    "href": "Untitled.html#session-2-itinerary",
    "title": "",
    "section": "Session 2 Itinerary",
    "text": "Session 2 Itinerary\nLiterate Statistical Programmi\n\nReview of R and RStudio\nLiterate programming is a programming paradigm\nResearch reproducibility reminders\nQuarto documents\nNext steps\n\nGoals:\n\nDescribe what makes programming “literate”\nExplain the real-life consequence of irreproducible research\nName one way Quarto can\n\n\nSo let’s get started with this second session. In this session we’re going to cover the concept of literate statistical programming and why it’s a great practice for data analysis. Literate statistical programming can be done in various languages, but we’ll talk about how to do it in R, using RStudio, in this webinar.\nLet’s start with a quick review of some of what we talked about in the first session of this two-part series."
  },
  {
    "objectID": "Untitled.html#r-vs-rstudio",
    "href": "Untitled.html#r-vs-rstudio",
    "title": "",
    "section": "R Vs RStudio",
    "text": "R Vs RStudio\n\n\n\n\n\n\n\n\nR Programming language for data analysis\n\nRStudio Integrated development environment (IDE)\n\n\nLast time we made an important distinction between R and RStudio.\nThe first logo you see here is for R. R is a statistical programming language that’s great for doing data analysis. We talked in the first session about a few things that make R useful:\n\nR was built specifically for statistical data analysis, so it’s got a friendly and focused user community and lots of great online resources for learning.\nR is open source, which means that it is “free” in two ways – in the meaning of having no cost and also in that can be used widely without intellectual property concerns or licensing restrictions.\nR makes it possible to work with data and build scripts that do lots of things, from ingesting data to building data visualizations.\n\nSo that’s R, it’s a language with a lot of benefits.\nThen, there’s RStudio. RStudio was the original name of a company as well as the name of a piece of software the company makes (and there is a free and a paid version of this software). A couple of years ago, the company changed its name from RStudio to Posit, but they kept the old name on at least some of their software.\nYou can think of RStudio (the software) as a fancy text editor for writing R code. The technical term for a fancy text editor for writing code is “Integrated Development Environment”, or I-D-E. You can run RStudio on Mac, Windows, or Linux. It can run on a local computer like your laptop, or on a server that is accessed using a web browser.\nYou don’t have to use RStudio to write R, but it makes it a lot easier. Think about typing a paper in Microsoft Word. You don’t need to use Word, necessarily. If you didn’t have Microsoft Word, you could write down your thoughts in Notepad, or in a blank Outlook email, or in the Notes app on your phone. But Microsoft Word has lots of add-ons, like spell-check and word count and formatting that make it much more pleasant to write a paper there, rather than in the notes app on your phone!"
  },
  {
    "objectID": "Untitled.html#literate-statistical-programming",
    "href": "Untitled.html#literate-statistical-programming",
    "title": "",
    "section": "Literate Statistical Programming",
    "text": "Literate Statistical Programming\nLiterate programming – Donald Knuth’s term for programming that is effective not just for computers but for people.\nStatistical programming – when you analyze data statistically, using a programming language.\nLiterate statistical programming – when you create scripts (for example in R) that describe for the computer and for human readers the analysis you’re doing and why and how you’re doing each step.\n\n“Literate programming” was coined decades ago by an important figure in computer science, Donald Knuth [pronounced Kuh-nuth, I think?]. He realized that while computer code was being consumed by, well, computers, it was also being consumed by humans, and it needed to be readable, and not just painfully, barely readable, but fluid and easy to read. It relies not just on a comment here or there, but on real documentation that is interlaced with code.\nWhen we combine that concept with the idea of statistical programming, where we’re analyzing data, we get literate statistical programming.\nLiterate Statistical Prgramming is what you do when you create a script, say for instance in R, and you go through the steps of ingesting, cleaning, analyzing, modeling, and displaying your data and findings, and you also describe what you’re doing in human language, with full paragraphs and headers and figure captions and bulleted lists and other notes that help you remember and help others learn what you’re doing and why.\nLet’s show you some examples!"
  },
  {
    "objectID": "Untitled.html#an-example",
    "href": "Untitled.html#an-example",
    "title": "",
    "section": "An Example",
    "text": "An Example\n ::: notes\nLast time, we showed you some of our analysis code, code we use to analyze our effectiveness in a webinar we give called “Arcus 101.”\nHere is a snippet of a script we wrote, and you can see that it has some description of what the code is doing, to help humans. We put in a header, to separate a section that has to do more with bringing the data in and cleaning it. Then we write a paragraph describing what we’re going to do, followed by a chunk of code.\nAfter that code executes, we’ll have some data. So we have some additional instructions, this time in the form of a bulleted list. I’m not showing you all of the code that makes that bulleted list happen, because it’s kind of long, but the code chunk with the grey background below that bulleted list does all the things in that bulleted list.\nHopefully, what this does is make it a lot easier for anyone on my team to pick up this code and work with it, even if they’re not the person who wrote the code. This is what literate statistical programming looks like, and working in R and RStudio is a great way to get started working this way.\nThis can help you create a kind of lab notebook that records each step you do with your data, in human language and in computer language. This is part of doing reproducible data analyses, which will reduce risk and make “future you” much happier. And I do want to talk briefly about the very real risks that can happen when people don’t do reproducible data analysis. :::"
  },
  {
    "objectID": "Untitled.html#the-duke-cancer-scandal",
    "href": "Untitled.html#the-duke-cancer-scandal",
    "title": "",
    "section": "The Duke Cancer Scandal",
    "text": "The Duke Cancer Scandal\n\n\n\nChemo sensitivity from microarrays\nSerious errors in data analysis\nClinical trials based on flawed models\nPapers retracted, lawsuits settled\n\n\n\n\n\nConsider the following case study, which highlights potential consequences of irreproducibile research, or research that’s really hard or impossible to re-do in the same way.\nA few years ago, researchers at Duke University tried to use microarray gene expression data of tumor cells to predict sensitivity to chemotherapeutic agents. This approach generated a lot of excitement at the time, and the resulting work was published in high-profile journals.\nUnfortunately, there were a number of serious errors in the data analysis.\nEven more unfortunately, patients were enrolled in clinical trials and allocated based on flawed models. It’s likely that some patients were actually treated with the chemo they are least likely to respond to rather than the chemo that’s most likely to work.\nIn the end, 18 papers were retracted, and Duke settled more than 10 lawsuits for an undisclosed amount of money."
  },
  {
    "objectID": "Untitled.html#an-easy-excel-slip-of-the-finger",
    "href": "Untitled.html#an-easy-excel-slip-of-the-finger",
    "title": "",
    "section": "An Easy Excel “Slip of the Finger”",
    "text": "An Easy Excel “Slip of the Finger”\n\n\nDuke\n\"1881_at\"\n\n\"31321_at\"\n\n\"31725_s_at\"\n\n\"32307_r_at\"\n\nMD Anderson\n\"1882_g_at\"\n\n\"31322_at\"\n\n\"31726_at\"\n\n\"32308_r_at\"\n\nDo you see the off-by-one indexing error?\n\nTwo biostatisticians at MD Anderson uncovered these mistakes in painstaking work. Let’s look at one of the errors they found.\nWhat you see on the left are the names of are a few of the hundreds of microarray probe sets – each roughly corresponds to a gene – that the Duke investigators reported to predict sensitivity to a particular chemotherapeutic agent..\nAnd on the right are the probe sets that the MD Anderson team got. You can see that they’re not the same.\nCan you see what went wrong?\nIf you look at the values long enough, you might notice a pattern: the number of the probe set that Duke reported is always one less than the number of the probe that MD Anderson found when they re-did the analysis.\nThis is what’s called an off-by-one indexing error. This happens when you use a tool like Excel and accidentally miss one row; or you have one dataset that has a header and another one that doesn’t. The result is that all the values in the affected column are shifted by one. This is a simple error to make, but it completely invalidates all downstream results."
  },
  {
    "objectID": "Untitled.html#common-problems-are-simple",
    "href": "Untitled.html#common-problems-are-simple",
    "title": "",
    "section": "“Common problems are simple…",
    "text": "“Common problems are simple…\n\nOff-by-one indexing error\nSensitive / resistant label reversal\nConfounding in experimental design\nInclusion of data from non-reported sources\nWrong figure shown\n\n… and simple problems are common.”\n\nThe off-by-one indexing error was just one of many simple errors the MD Anderson team discovered.\nAnother type of error that was pervasive in the study was label reversal; cell lines were labeled sensitive to a drug when they actually were resistant, and vice versa. That type of error can lead to a scenario where a patient gets the chemotherapy that would be predicted to be least beneficial.\nOther problems they identified were confounding, inclusion of data from sources that were not reported in the paper, and wrong figure shown.\nThese are all simple errors – people who make them aren’t necessarily incompetent or negligent.\nBecause these errors are so easy to make and because without good documentation or a reproducible workflow it’s hard to catch them, they are also very common."
  },
  {
    "objectID": "Untitled.html#point-and-click",
    "href": "Untitled.html#point-and-click",
    "title": "",
    "section": "Point-and-Click…",
    "text": "Point-and-Click…\n… is not reproducible!\n\n\nA key issue in this case study is that the Duke investigators used “point and click” tools like Excel, without automated scripts. There was a lot of manual human intervention here that was really labor intensive and had lots of steps.\nThis prevented peers and independent investigators from catching errors in the analysis, until it was too late.\nUnfortunately, the Duke case study is only one example where the barrier to reproducibility was that people used “point-and-click” type tools for analyzing large and complicated sets of data. There are lots of other examples of where point and click analysis has resulted in analyses being wrong. Now, with the right safeguards, Excel CAN be the right fit for some simple one-off things you’re doing, but for high-stakes things like research results, it can hide your mistakes and compound them. No one wants that!"
  },
  {
    "objectID": "Untitled.html#reproducibility-helps-teams-of-one",
    "href": "Untitled.html#reproducibility-helps-teams-of-one",
    "title": "",
    "section": "Reproducibility Helps “Teams of One”",
    "text": "Reproducibility Helps “Teams of One”\n\nCan we redo the analysis with this month’s data?\nWhy do the data in Table 1 not seem to agree with Figure 2?\nWhy did I decide to omit these six samples from my analysis?\n\nYour closest collaborator is you from 6 months ago…\n\nReproducibility doesn’t only help people outside a study understand how things were done. They also help the initial conduct of research as well. Consider the following 3 statements and ask yourself if they sound familiar.\n\nCan we redo the analysis with this month’s data?\nWhy do the data in Table 1 not seem to agree with Figure 2?\nWhy did I decide to omit these six samples from my analysis?\n\nYour closest collaborator is you from 6 months ago…\n… but past you can’t answer your emails!\nIf you use data cleaning and data analysis scripts in R, scripts that record each step you do in code, it can be much easier to retrace your steps or rerun your entire analysis with just a couple of clicks to re-run the script. You could, for example, have a script that goes and gets the latest data directly from REDCap, removes any outliers according to pre-established rules, does some statistical tests on two groups, creates a table and data visualization, and saves all of that in a .pdf that is already formatted with the special rules of the journal you want to submit to. You could keep collecting data via REDCap and simply re-run that script with a single click and get an updated report. This will make your life easier in the long run, even though it means an up-front investment of writing code."
  },
  {
    "objectID": "Untitled.html#introducing-quarto",
    "href": "Untitled.html#introducing-quarto",
    "title": "",
    "section": "Introducing Quarto",
    "text": "Introducing Quarto\n\n\nI hope I have convinced you that reproducibility is important, and that literate statistical programming can help make your data analysis more reproducible.\nOne way to start doing literate statistical programming is to use Quarto, and another is a very similar document format that preceded Quarto and is very much like it, called R Markdown. My team’s code that analyzes our survey data is a Quarto document.\nQuarto and R Markdown allow you to write computer code mixed in with English (or other human language) narrative annotation that documents the purpose of the code and details about the decisions you made in your analysis.\nQuarto documents are composed of 3 basic types of building blocks.\nThe first is the header which includes information about the document, such as its title, author, and the desired output format when the document is rendered. A lot of this information is optional so a header can be pretty short, like the one we see here, or much longer.\nThe second type of building block is text. Text can include special kinds of marks (Markdown) that add styling. This includes hash marks that turn a line of text into a header, asterisks that can create italics, lines of dashes that turn into horizontal lines, and more. Markdown is used everywhere in tech, not just in R Markdown or Quarto. Markdown is useful to learn if you’re going to use GitHub, or Python, or LaTex, or just about anything in the tech world where you’re expected to write some sort of documentation.\nThe third is code chunks. Code chunks contain R code that can be executed to output results."
  },
  {
    "objectID": "Untitled.html#running-a-single-code-chunk",
    "href": "Untitled.html#running-a-single-code-chunk",
    "title": "",
    "section": "Running a Single Code Chunk",
    "text": "Running a Single Code Chunk\n\nCan you see the green “play” button?\nThat’s how you run this chunk!\n\nSo how do you execute the code in the code chunks? There are a couple of ways.\nThe first is to run the code in a single code chunk. And you do this by clicking the green right-pointing triangle on the top right of the chunk. This symbol looks like a “play” button. There are other symbols, too, including one that means “run all the code chunks that came before this one”."
  },
  {
    "objectID": "Untitled.html#rendering",
    "href": "Untitled.html#rendering",
    "title": "",
    "section": "Rendering",
    "text": "Rendering\nYou will see (“Knit”/“Preview” instead of “Render” in R Markdown documents)\n\n\n\n\n\n\n\nThe second way to execute code is to convert the entire Quarto document into HTML (or another target format). For now we’ll stick to HTML because it’s the default and usually what you want. This process of converting Quarto into a target format is called “rendering”.\nTo render a document, click the button that says “Render”. Then in a few moments, a rendered document will be shown.\nIf you are working in R Markdown, like R Notebooks, you’ll see the word “Preview” or “Knit” instead. That also acts to render the Markdown."
  },
  {
    "objectID": "session_2.html#welcome",
    "href": "session_2.html#welcome",
    "title": "",
    "section": "Welcome",
    "text": "Welcome\nThese slides available at: https://arcus.github.io/demystifying_r_rstudio_skills_series/session_2.html\n\nUse keyboard arrow keys to\n\nadvance ( → ) and\ngo back ( ← )\n\nType “s” to see speaker notes\nType “?” to see other keyboard shortcuts\n\n\nAs we prepare to get started, I’d like to encourage you to open these slides on your own browser, so you will have them available to refer to later. There are also a number of links you may want to click on. I’ll copy paste that URL, where the slide deck is located, into chat, so everyone has it.\nThis first slide is just to help you navigate this slide deck if you look at these slides on your own! And yes, there are ample speaker notes, so if you missed something I said, chances are it’s going to be in the speaker notes of the slide."
  },
  {
    "objectID": "session_2.html#about-arcus-your-presenter",
    "href": "session_2.html#about-arcus-your-presenter",
    "title": "",
    "section": "About Arcus / Your Presenter",
    "text": "About Arcus / Your Presenter\n\n\nArcus is an initiative by the Research Institute aimed at promoting data discovery and reuse and increasing research reproducibility.\n\nArcus app: https://arcus.chop.edu\nArcus Sharepoint site: https://chop365.sharepoint.com/sites/Arcus\n\nAmong the many teams in Arcus, I represent Arcus Education!\n\n\n\n\n\nThanks again for joining us, and welcome to our session today! I’d like to begin by briefly introducing myself and introducing Arcus, for those of you who may not be familiar with us. My name is ______ [add pronouns here if you want], and I’ll be leading today’s session.\nArcus is an initiative by the Research Institute aimed at promoting data discovery and reuse and increasing research reproducibility throughout the research lifecycle, as you can see in the graphic on the right. [Pause, give folks a few secs to peruse the image].\nChanging the paradigm of research is a big undertaking, and it requires a broad approach.\nWe aim to improve data reuse and research reproducibility at CHOP through technology, including Arcus labs and applied data science, through the use of data archiving and cataloging, and by way of education.\nYou can find out more by checking out the Arcus application website (please note, there are some pre-requisites to using the app, such as human subjects protection training and signing our terms of use). I’ve added just a very small screenshot of part of what the Arcus application website looks like on the slide on the left side. [Pause].\nYou can also, without any prerequisites, look at our Arcus Sharepoint site, which has a calendar of events and lots more information about Arcus.\nAnd finally, a little more about me: I work in Arcus Education. Our role is to support CHOP scientists by helping researchers acquire data science skills. That’s why we have Skills Series like this one!"
  },
  {
    "objectID": "session_2.html#arcus-education",
    "href": "session_2.html#arcus-education",
    "title": "",
    "section": "Arcus Education",
    "text": "Arcus Education\n\n\n\n\nArcus education provides data science training to researchers …\n(and often this is useful to non-researchers too!).\nhttps://arcus.chop.edu/i-want-to/arcus-education\nEmail us! arcus-education@chop.edu\n\n\nThe Arcus Education team does lots of different kinds of education. We work one on one with researchers in office hours, we write how-to guides to help people understand how to use Arcus tools, we create asynchronous modules that people can use to acquire skills in their own time, and we do synchronous events like this one.\nSometimes we focus on Arcus customers, on researchers at CHOP who are doing research within the Arcus data sharing paradigm, and sometimes we broaden our reach to larger audiences, because we know that helping everyone acquire data science skills will help improve the conduct of science at CHOP and help build a data-driven workforce.\nPlease check out that education page and find out more about some of our services. You can see I’ve added a screenshot of that page to the slide here on the left side. You can also email us at arcus dash education at chop dot edu."
  },
  {
    "objectID": "session_2.html#demystifying-r-and-rstudio",
    "href": "session_2.html#demystifying-r-and-rstudio",
    "title": "",
    "section": "Demystifying R and RStudio",
    "text": "Demystifying R and RStudio\nArcus Education provides “Skills Series” for the entire CHOP community.\nThis Skills Series is a short, 2-session series aimed at Demystifying R and RStudio!\n\nSession 1: Introduction to R/RStudio\nSession 2: Introduction to Literate Statistical Programming\n\n\nOne of our methods in Education is the Skills Series, and that’s what you’re in today.\nIn this series, we’re going to take just two sessions to help demystify R and RStudio. If you have heard people talk about these concepts and you have only a vague idea what they are, and want to know more, without having to actually download anything or write code, at least not yet, this is the right series for you.\nAfter you finish these two sessions, you’ll understand what R is, what RStudio is, why people use these tools, and next steps for getting access to them, if you want."
  },
  {
    "objectID": "session_2.html#session-2-itinerary",
    "href": "session_2.html#session-2-itinerary",
    "title": "",
    "section": "Session 2 Itinerary",
    "text": "Session 2 Itinerary\nLiterate Statistical Programmi\n\nReview of R and RStudio\nLiterate programming is a programming paradigm\nResearch reproducibility reminders\nQuarto documents\nNext steps\n\nGoals:\n\nDescribe what makes programming “literate”\nExplain the real-life consequence of irreproducible research\nName one way Quarto documents can be helpful in data analysis\n\n\nSo let’s get started with this second session. In this session we’re going to cover the concept of literate statistical programming and why it’s a great practice for data analysis. Literate statistical programming can be done in various languages, but we’ll talk about how to do it in R, using RStudio, in this webinar.\nLet’s start with a quick review of some of what we talked about in the first session of this two-part series."
  },
  {
    "objectID": "session_2.html#r-vs-rstudio",
    "href": "session_2.html#r-vs-rstudio",
    "title": "",
    "section": "R Vs RStudio",
    "text": "R Vs RStudio\n\n\n\n\n\n\n\n\nR Programming language for data analysis\n\nRStudio Integrated development environment (IDE)\n\n\nLast time we made an important distinction between R and RStudio.\nThe first logo you see here is for R. R is a statistical programming language that’s great for doing data analysis. We talked in the first session about a few things that make R useful:\n\nR was built specifically for statistical data analysis, so it’s got a friendly and focused user community and lots of great online resources for learning.\nR is open source, which means that it is “free” in two ways – in the meaning of having no cost and also in that can be used widely without intellectual property concerns or licensing restrictions.\nR makes it possible to work with data and build scripts that do lots of things, from ingesting data to building data visualizations.\n\nSo that’s R, it’s a language with a lot of benefits.\nThen, there’s RStudio. RStudio was the original name of a company as well as the name of a piece of software the company makes (and there is a free and a paid version of this software). A couple of years ago, the company changed its name from RStudio to Posit, but they kept the old name on at least some of their software.\nYou can think of RStudio (the software) as a fancy text editor for writing R code. The technical term for a fancy text editor for writing code is “Integrated Development Environment”, or I-D-E. You can run RStudio on Mac, Windows, or Linux. It can run on a local computer like your laptop, or on a server that is accessed using a web browser.\nYou don’t have to use RStudio to write R, but it makes it a lot easier. Think about typing a paper in Microsoft Word. You don’t need to use Word, necessarily. If you didn’t have Microsoft Word, you could write down your thoughts in Notepad, or in a blank Outlook email, or in the Notes app on your phone. But Microsoft Word has lots of add-ons, like spell-check and word count and formatting that make it much more pleasant to write a paper there, rather than in the notes app on your phone!"
  },
  {
    "objectID": "session_2.html#literate-statistical-programming",
    "href": "session_2.html#literate-statistical-programming",
    "title": "",
    "section": "Literate Statistical Programming",
    "text": "Literate Statistical Programming\nLiterate programming – Donald Knuth’s term for programming that is effective not just for computers but for people.\nStatistical programming – when you analyze data statistically, using a programming language.\nLiterate statistical programming – when you create scripts (for example in R) that describe for the computer and for human readers the analysis you’re doing and why and how you’re doing each step.\n\n“Literate programming” was coined decades ago by an important figure in computer science, Donald Knuth [pronounced Kuh-nuth, I think?]. He realized that while computer code was being consumed by, well, computers, it was also being consumed by humans, and it needed to be readable, and not just painfully, barely readable, but fluid and easy to read. It relies not just on a comment here or there, but on real documentation that is interlaced with code.\nWhen we combine that concept with the idea of statistical programming, where we’re analyzing data, we get literate statistical programming.\nLiterate Statistical Prgramming is what you do when you create a script, say for instance in R, and you go through the steps of ingesting, cleaning, analyzing, modeling, and displaying your data and findings, and you also describe what you’re doing in human language, with full paragraphs and headers and figure captions and bulleted lists and other notes that help you remember and help others learn what you’re doing and why.\nLet’s show you an example!"
  },
  {
    "objectID": "session_2.html#an-example",
    "href": "session_2.html#an-example",
    "title": "",
    "section": "An Example",
    "text": "An Example\n\n\n\n\nWe describe what we do and use headers, bullet points, and other formatting to make it easier for humans to make sense of the code.\n\n\nLast time, we showed you some of our analysis code, code we use to analyze our effectiveness in a webinar we give called “Arcus 101.”\nHere is a snippet of a script we wrote, and you can see that it has some description of what the code is doing, to help humans. We put in a header, to separate a section that has to do more with bringing the data in and cleaning it. Then we write a paragraph describing what we’re going to do, followed by a chunk of code.\nAfter that code executes, we’ll have some data. So we have some additional instructions, this time in the form of a bulleted list. I’m not showing you all of the code that makes that bulleted list happen, because it’s kind of long, but the code chunk with the grey background below that bulleted list does all the things in that bulleted list.\nHopefully, what this does is make it a lot easier for anyone on my team to pick up this code and work with it, even if they’re not the person who wrote the code. This is what literate statistical programming looks like, and working in R and RStudio is a great way to get started working this way.\nThis can help you create a kind of lab notebook that records each step you do with your data, in human language and in computer language. This is part of doing reproducible data analyses, which will reduce risk and make “future you” much happier. And I do want to talk briefly about the very real risks that can happen when people don’t do reproducible data analysis."
  },
  {
    "objectID": "session_2.html#the-duke-cancer-scandal",
    "href": "session_2.html#the-duke-cancer-scandal",
    "title": "",
    "section": "The Duke Cancer Scandal",
    "text": "The Duke Cancer Scandal\n\n\n\nChemo sensitivity from microarrays\nSerious errors in data analysis\nClinical trials based on flawed models\nPapers retracted, lawsuits settled\n\n\n\n\n\nConsider the following case study, which highlights potential consequences of irreproducibile research, or research that’s really hard or impossible to re-do in the same way.\nA few years ago, researchers at Duke University tried to use microarray gene expression data of tumor cells to predict sensitivity to chemotherapeutic agents. This approach generated a lot of excitement at the time, and the resulting work was published in high-profile journals.\nUnfortunately, there were a number of serious errors in the data analysis.\nEven more unfortunately, patients were enrolled in clinical trials and allocated based on flawed models. It’s likely that some patients were actually treated with the chemo they are least likely to respond to rather than the chemo that’s most likely to work.\nIn the end, 18 papers were retracted, and Duke settled more than 10 lawsuits for an undisclosed amount of money."
  },
  {
    "objectID": "session_2.html#an-easy-excel-slip-of-the-finger",
    "href": "session_2.html#an-easy-excel-slip-of-the-finger",
    "title": "",
    "section": "An Easy Excel “Slip of the Finger”",
    "text": "An Easy Excel “Slip of the Finger”\n\n\nDuke\n\"1881_at\"\n\n\"31321_at\"\n\n\"31725_s_at\"\n\n\"32307_r_at\"\n\nMD Anderson\n\"1882_g_at\"\n\n\"31322_at\"\n\n\"31726_at\"\n\n\"32308_r_at\"\n\nDo you see the off-by-one indexing error?\n\nTwo biostatisticians at MD Anderson uncovered these mistakes in painstaking work. Let’s look at one of the errors they found.\nWhat you see on the left are the names of are a few of the hundreds of microarray probe sets – each roughly corresponds to a gene – that the Duke investigators reported to predict sensitivity to a particular chemotherapeutic agent..\nAnd on the right are the probe sets that the MD Anderson team got. You can see that they’re not the same.\nCan you see what went wrong?\nIf you look at the values long enough, you might notice a pattern: the number of the probe set that Duke reported is always one less than the number of the probe that MD Anderson found when they re-did the analysis.\nThis is what’s called an off-by-one indexing error. This happens when you use a tool like Excel and accidentally miss one row; or you have one dataset that has a header and another one that doesn’t. The result is that all the values in the affected column are shifted by one. This is a simple error to make, but it completely invalidates all downstream results."
  },
  {
    "objectID": "session_2.html#common-problems-are-simple",
    "href": "session_2.html#common-problems-are-simple",
    "title": "",
    "section": "“Common problems are simple…",
    "text": "“Common problems are simple…\n\nOff-by-one indexing error\nSensitive / resistant label reversal\nConfounding in experimental design\nInclusion of data from non-reported sources\nWrong figure shown\n\n… and simple problems are common.”\n\nThe off-by-one indexing error was just one of many simple errors the MD Anderson team discovered.\nAnother type of error that was pervasive in the study was label reversal; cell lines were labeled sensitive to a drug when they actually were resistant, and vice versa. That type of error can lead to a scenario where a patient gets the chemotherapy that would be predicted to be least beneficial.\nOther problems they identified were confounding, inclusion of data from sources that were not reported in the paper, and wrong figure shown.\nThese are all simple errors – people who make them aren’t necessarily incompetent or negligent.\nBecause these errors are so easy to make and because without good documentation or a reproducible workflow it’s hard to catch them, they are also very common. Now, not all of these problems could have been fixed just by using literate statistical programming, but some of the really important ones could have been fixed or at least detected a lot more quickly, possibly before patients were harmed and before papers went to press."
  },
  {
    "objectID": "session_2.html#point-and-click",
    "href": "session_2.html#point-and-click",
    "title": "",
    "section": "Point-and-Click…",
    "text": "Point-and-Click…\n… is not as reproducible as literate statistical programming!\n\n\nA key issue in this case study is that the Duke investigators used “point and click” tools like Excel, without automated scripts, without using a literate statistical programming approach. There was a lot of manual human intervention here involving the use of spreadsheets… work that was really labor intensive and had lots of steps.\nThis prevented peers and independent investigators from catching errors in the analysis, until it was too late.\nUnfortunately, the Duke case study is only one example where the barrier to reproducibility was that people used “point-and-click” type tools for analyzing large and complicated sets of data. There are lots of other examples of where point and click analysis has resulted in analyses being wrong. Now, with the right safeguards, Excel CAN be the right fit for some simple one-off things you’re doing, but for high-stakes things like research results, it can hide your mistakes and compound them. No one wants that!"
  },
  {
    "objectID": "session_2.html#are-you-a-team-of-one",
    "href": "session_2.html#are-you-a-team-of-one",
    "title": "",
    "section": "Are You a “Team of One” ?",
    "text": "Are You a “Team of One” ?\n\nCan I redo the analysis with this month’s data?\nWhy do the data in Table 1 not seem to agree with Figure 2?\nWhy did I decide to omit these six samples from my analysis?\n\nYour closest collaborator is you from 6 months ago…\n\nUsing scripts to document your work in a literate statistical programming approach doesn’t only help people outside a study understand how things were done. They also help the initial conduct of research as well. Consider the following 3 statements and ask yourself if they sound familiar.\n\nCan I redo the analysis with this month’s data? Can I do it in a hurry?\nWhy do the data in Table 1 not seem to agree with Figure 2?\n\nWhy did I decide to omit these six samples from my analysis?\n\nKeep in mind, your closest collaborator is you from 6 months ago, but past you can’t answer your emails!\nIf you use literate data analysis scripts in R, scripts that record each step you do in code and in human language, it can be much easier to retrace your steps or rerun your entire analysis with just a couple of clicks to re-run the script. You could, for example, have a script that goes and gets the latest data directly from REDCap, removes any outliers according to pre-established rules, does some statistical tests on two groups, creates a table and data visualization, and saves all of that in a .pdf that is already formatted with the special rules of the journal you want to submit to. You could keep collecting data via REDCap and simply re-run that script with a single click and get an updated report. This will make your life easier in the long run, even though it means an up-front investment of writing code."
  },
  {
    "objectID": "session_2.html#introducing-quarto",
    "href": "session_2.html#introducing-quarto",
    "title": "",
    "section": "Introducing Quarto",
    "text": "Introducing Quarto\n\n\nI hope I have convinced you that literate statistical programming can help make your data analysis more reproducible, and that this can have really important consequences.\nOne way to start doing literate statistical programming is to use Quarto, and another is a very similar document format that preceded Quarto and is very much like it, called R Markdown. My team’s code that analyzes our survey data, the code you’ve seen already, is a Quarto document.\nQuarto and R Markdown allow you to write computer code mixed in with human language that documents the purpose of the code and details about the decisions you made in your analysis.\nQuarto documents are composed of 3 basic types of building blocks.\nThe first is the header which includes information about the document, such as its title, author, and the desired output format when the document is rendered. A lot of this information is optional so a header can be pretty short, like the one we see here, or much longer.\nThe second type of building block is text. Text can include special kinds of marks (Markdown) that add styling. This includes hash marks that turn a line of text into a header, asterisks that can create italics, lines of dashes that turn into horizontal lines, and more. Markdown is used everywhere in tech, not just in R Markdown or Quarto. Markdown is useful to learn if you’re going to use GitHub, or Python, or LaTex [pronounced “lah-tek”], or make posts on Stack Overflow, or use Reddit, or just about anything in the tech world where you’re expected to write some sort of documentation.\nThe third is code chunks. Code chunks contain R code that can be executed to output results."
  },
  {
    "objectID": "session_2.html#output-formats",
    "href": "session_2.html#output-formats",
    "title": "",
    "section": "Output Formats",
    "text": "Output Formats\n\n\n\n\nQuarto allows you create documents that interlace:\n\nYour reasoning about your code\nThe code you write\nThe output of the code you write\n\nWhich helps future-you AND your colleagues!\n\n\nYou can use a Quarto or R Markdown document interactively, and run code from within it. You could run a single code chunk to ingest data and just stop there, for example. But you can also use this kind of script to make a final output document, like a short html file, a slide deck, a manuscript you want to have a in .pdf format, or even a whole website. In fact, the online slide deck I’m presenting from was built in Quarto. These slides, which use html and javascript, were written in RStudio, using Markdown, and if I wanted to, I could run R code inside these slides.\nTo make an output document, you click a button in RStudio. The button might say “Render”, “Preview”, or “Knit”, depending on the kind of document you’re creating, and whether you’re working in Quarto or R Markdown. The words all mean the same thing."
  },
  {
    "objectID": "session_2.html#qa-was-this-effective",
    "href": "session_2.html#qa-was-this-effective",
    "title": "",
    "section": "Q&A / Was This Effective?",
    "text": "Q&A / Was This Effective?\nAs you can tell from our data analysis, we like to measure our effectiveness.\nGoals:\n\nDescribe what makes programming “literate”\nExplain the real-life consequence of irreproducible research\nName one way Quarto documents can be helpful in data analysis\n\n\nNow, this is not the final slide, but we’re a group that likes to measure our effectiveness and make changes based on what we learn. So before we do questions and answers, we like to make sure to give our learners a poll to see if we made a good use of your time. We’re going to ask if we were effective in reaching our goals today, and those goals are on the screen in order to help you answer that question. Once you answer that poll, feel free to type a question into chat or come off mute and ask to clarify anything I can explain a bit better. I’ll stop our session of Q&A with about 5 minutes to spare because I do have just a couple of finishing slides I want to show."
  },
  {
    "objectID": "session_2.html#homework",
    "href": "session_2.html#homework",
    "title": "",
    "section": "Homework",
    "text": "Homework\nIf you want, totally optional additional learning:\n\n\n\nModule\nDescription\nDuration\n\n\n\n\nLearning to Learn Data Science\nDiscover how learning data science is different than learning other subjects.\n20 mins\n\n\nReproducibility, Generalizability, and Reuse\nThis module provides learners with an approachable introduction to the concepts and impact of research reproducibility….\n60 min\n\n\nR Basics\nAre you brand new to R, and ready to get started? This module teaches concepts and vocabulary related to R, RStudio, and R Markdown….\n60 min\n\n\n\n\nAn article on Excel in research, with some warnings and some next steps for risk mitigation\n\n\nOK, as we get close to the end, I know that for some people, this topic ignited a bit of excitement about the ideas around learning how to code or learning more about reproducibility. I’ve also added R Basics. These are all examples of some of our asynchronous modules which I mentioned earlier, and there are over sixty of these modules, so try checking these out.\nAnd, if you’re an Excel user, and you want to understand the risks of using Excel and how to mitigate them, there’s an article here that might be interesting to read.\nWith that, I want to thank you for your time and enthusiasm today. Your time is an incredibly valuable resource and I hope that this webinar series was a good use of it. If there’s any feedback, positive or negative, that you’d be willing to offer, please feel free to drop me a line or email arcus dash education at chop dot edu.\n\n\n\n\n\nArcus Education, Children’s Hospital of Philadelphia"
  },
  {
    "objectID": "session_2.html#easy-to-make-mistakes",
    "href": "session_2.html#easy-to-make-mistakes",
    "title": "",
    "section": "Easy to make mistakes",
    "text": "Easy to make mistakes\n\nOff-by-one indexing error\nSensitive / resistant label reversal\nConfounding in experimental design\nInclusion of data from non-reported sources\nWrong figure shown\n\n… add up to huge patient consequences!\n\nThe off-by-one indexing error was just one of many simple errors the MD Anderson team discovered.\nThese errors are so easy to make. Without good documentation or a reproducible workflow, it’s also very hard to catch them. Now, not all of these problems could have been fixed just by using literate statistical programming, but some of the really important ones could have been fixed or at least detected a lot more quickly, possibly before patients were harmed and before papers went to press.\nA key issue in this case study is that the Duke investigators used “point and click” tools like Excel, without automated scripts, without using a literate statistical programming approach. There was a lot of manual human intervention here involving the use of spreadsheets… work that was really labor intensive and had lots of steps, many of which were probably never written down but just kept in people’s heads.\nThis prevented peers and independent investigators from catching errors in the analysis, until it was too late.\nUnfortunately, the Duke case study is only one example where the barrier to reproducibility was that people used “point-and-click” type tools for analyzing large and complicated sets of data. There are lots of other examples of where point and click analysis has resulted in analyses being wrong. Now, with the right safeguards, Excel CAN be the right fit for some simple one-off things you’re doing, but for high-stakes things like research results, it can hide your mistakes and compound them. No one wants that!"
  },
  {
    "objectID": "session_2.html#ready-to-try",
    "href": "session_2.html#ready-to-try",
    "title": "",
    "section": "Ready to Try?",
    "text": "Ready to Try?\n\nGet access to R and RStudio!\n\nPosit.cloud (just for learning, NOT for working in CHOP data)\nAsk to get R and RStudio installed (and consider Git and GitHub, too!)\n\nLearn a little basic R\n\nWe suggest learning “tidyverse” and working with data frames first\nWe very strongly suggest learning within the context of RStudio\nArcus has some resources (live/synchronous and asynchronous)\nSo do lots of other people! Consider how you like to learn.\n\nJoin CHOP’s R User Group\nPick one task you do manually and try to re-do it in R\nDon’t be afraid to fail (I do!)\n\n\nIf what you’ve learned today, and possibly in the first session, has inspired you to want to learn to write R code and to use RStudio to do that, there are lots of ways to do that.\nFirst, do get access to R and RStudio so you can use these tools.\nSecond, learn to use R! We have some offerings, but we’re certainly not the only game in town. How do you like to learn? Are you motivated by grades, and you really thrive in a class setting? Many universities offer courses in R, often related to things like biostatistics or public health. Do you like videos and short-form courses that you get a certificate for? Coursera and other massive open online course providers have great R courses, which again can sometimes be related to a specific interest, like Bayesian statistics or data visualization. Do you prefer books? There are some great books out there, especially ones by people like Hadley Wickham and Garrett Grolemund. In the next few slide we’ll have some links for CHOP-based resources, but please know that there’s a wealth of other stuff out there that you may also really enjoy.\nCHOP has also had an R user group for a number of years, and we encourage you to join it! There’s a mailing list as well as a Slack workspace that people use to communicate, share successes, ask questions, and get advice.\nLearning to code is like learning a sport – you have to do it and build muscle memory. So take something you do regularly, whether that’s analyzing your department’s budget, or reporting on recruitment for your study, or looking at infection prevalence on your floor, or even looking at the data from your favorite sports team or political party… take one thing that you do using a point and click, manual approach, and try to move it to analysis with R. At first you’ll feel like it’s awkward and hard, like you’re writing with your non-dominant hand. But after a while, you’ll gain skills and figure out how to apply what you’ve learned to other tasks.\nAnd finally, writing code is hard! But your whole job is hard, or at least it was hard at first, before you learned the skills, right? So when it feels like you just keep messing up, I want to encourage you by saying that I fail too. I not only write R to analyze data, but I teach this stuff, and I still mess up, have to Google things, need to ask for help, and learn new things from my colleagues. So please be kind to yourselves as you learn."
  },
  {
    "objectID": "session_2.html#getting-access-to-r-rstudio",
    "href": "session_2.html#getting-access-to-r-rstudio",
    "title": "",
    "section": "Getting Access to R / RStudio",
    "text": "Getting Access to R / RStudio\n\nSlide titled Working with R at CHOP\nSlide titled What to Get Installed\nSlide titled Researchers ONLY at CHOP\nSlide titled Posit.Cloud (be careful!)\n\n\nThere are some detailed slides we went over in the first session of this series, and I’m just going to give those links here. Please check these out, these have helpful links!"
  },
  {
    "objectID": "session_2.html#r-at-chop",
    "href": "session_2.html#r-at-chop",
    "title": "",
    "section": "R at CHOP",
    "text": "R at CHOP\n\nJoin the CHOP R User Group\nCheck out some asynchrounous modules\nWe will have some upcoming Skills Series related to R: Join the CHOP R User Group to be the first to find out the dates!\n\n\nAnd as promised, a few links here. You can join the CHOP R User Group and check out some asynchronous modules my team built, which you can use to learn R in small bits of time, like on your lunch break. Additionally, we plan to have additional Skills Series like this one. This Skills Series was a short one of only two sessions, but our next one will be entitled “First Steps in R and RStudio”, and will be 6 sessions in length and will help you get started writing code for the first time. Keep your eyes open for an announcement about that in the R User Group or on the Arcus Sharepoint page!"
  }
]